---
title: "Qualitative Coding with GPT-4: Where it Works Better"
collection: publications
category: manuscripts
permalink: /publication/2025-gpt-automated-coding
excerpt: 'This study explores the potential of the large language model GPT-4 as an automated tool for qualitative data analysis by educational researchers, exploring which techniques are most successful for different types of constructs. Specifically, we assess three different prompt engineering strategies—Zero-shot, Few-shot, and Few-shot with contextual information—as well as the use of embeddings. Our findings suggest that while GPT-4 can code a broad range of constructs, no single method consistently outperforms the others, and the selection of a particular method should be tailored to the specific properties of the construct and context being analyzed.'
date: 2025-05-01
venue: 'Journal of Learning Analytics'
paperurl: 'https://www.learning-analytics.info/index.php/JLA/article/view/8575'
---

This study explores the potential of the large language model GPT-4 as an automated tool for qualitative data analysis by educational researchers, exploring which techniques are most successful for different types of constructs. Specifically, we assess three different prompt engineering strategies—Zero-shot, Few-shot, and Few-shot with contextual information—as well as the use of embeddings. We do so in the context of qualitatively coding three distinct educational datasets: Algebra I semi-personalized tutoring session transcripts, student observations in a game-based learning environment, and debugging behaviours in an introductory programming course. We evaluated the performance of each approach based on its inter-rater agreement with human coders and explored how different methods vary in effectiveness depending on a construct’s degree of clarity, concreteness, objectivity, granularity, and specificity. Our findings suggest that while GPT-4 can code a broad range of constructs, no single method consistently outperforms the others, and the selection of a particular method should be tailored to the specific properties of the construct and context being analyzed. We also found that GPT-4 has the most difficulty with the same constructs that human coders find more difficult to reach inter-rater reliability on.

citation: 'Liu, X., Zambrano, A. F., Baker, R. S., Barany, A., Ocumpaugh, J., Zhang, J., Pankiewicz, M., Nasiar, N., & Wei, Z. (2025). &quot;Qualitative Coding with GPT-4: Where it Works Better.&quot; <i>Journal of Learning Analytics</i>, 12(1), 169-185. https://doi.org/10.18608/jla.2025.8575'
